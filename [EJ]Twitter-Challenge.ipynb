{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 01: Module and API Set-Up ####\n",
    "\n",
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 02-1: Twitter API Pull for BBC News ####\n",
    "\n",
    "# Target User Account\n",
    "target_account=\"@BBCNews\"\n",
    "\n",
    "for target_user in target_account:\n",
    "\n",
    "    # Counter\n",
    "    counter = 0\n",
    "\n",
    "# Variables for holding sentiments\n",
    "timestamp_list = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "text_list = []\n",
    "tweets_ago_list = []\n",
    "handle_list = []\n",
    "\n",
    "# Loop through 5 pages of tweets (total 100 tweets)\n",
    "for x in range(1, 6):\n",
    "\n",
    "    # Get all tweets from home feed\n",
    "    public_tweets = api.user_timeline(target_account, page=x)\n",
    "\n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "\n",
    "        # VADER: Run Vader Analysis on each tweet\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "        \n",
    "        # Counter and Timestamp\n",
    "        counter+= 1\n",
    "        tweet_time = tweet[\"created_at\"]        \n",
    "        \n",
    "        # VADER: Add each value to the appropriate list\n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "\n",
    "        # Twitter Handle\n",
    "        handle_list.append(tweet[\"user\"][\"screen_name\"])\n",
    "\n",
    "        # Add Text to list\n",
    "        text_list.append(tweet[\"text\"])\n",
    "\n",
    "        # Add counter to list\n",
    "        tweets_ago_list.append(counter)\n",
    "\n",
    "        # Add Timestamp to list\n",
    "        timestamp_list.append(tweet_time)\n",
    "        \n",
    "# Turn into DataFrame\n",
    "df_bbc=pd.DataFrame(list(zip(handle_list,tweets_ago_list,timestamp_list,\n",
    "                         compound_list,positive_list,negative_list,neutral_list,text_list)))\n",
    "\n",
    "\n",
    "### 02-2: Twitter API Pull for CBS News ####\n",
    "\n",
    "# Target User Account\n",
    "target_account=\"@CBSNews\"\n",
    "\n",
    "for target_user in target_account:\n",
    "    counter = 0\n",
    "\n",
    "timestamp_list = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "text_list = []\n",
    "tweets_ago_list = []\n",
    "handle_list = []\n",
    "\n",
    "for x in range(1, 6):\n",
    "    public_tweets = api.user_timeline(target_account, page=x)\n",
    "    for tweet in public_tweets:\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "        counter+= 1\n",
    "        tweet_time = tweet[\"created_at\"]        \n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "        handle_list.append(tweet[\"user\"][\"screen_name\"])\n",
    "        text_list.append(tweet[\"text\"])\n",
    "        tweets_ago_list.append(counter)\n",
    "        timestamp_list.append(tweet_time)\n",
    "        \n",
    "# Turn into DataFrame\n",
    "df_cbs=pd.DataFrame(list(zip(handle_list,tweets_ago_list,timestamp_list,\n",
    "                         compound_list,positive_list,negative_list,neutral_list,text_list)))\n",
    "\n",
    "### 02-3: Twitter API Pull for CNN ####\n",
    "\n",
    "# Target User Account\n",
    "target_account=\"@CNN\"\n",
    "\n",
    "for target_user in target_account:\n",
    "    counter = 0\n",
    "\n",
    "timestamp_list = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "text_list = []\n",
    "tweets_ago_list = []\n",
    "handle_list = []\n",
    "\n",
    "for x in range(1, 6):\n",
    "    public_tweets = api.user_timeline(target_account, page=x)\n",
    "    for tweet in public_tweets:\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "        counter+= 1\n",
    "        tweet_time = tweet[\"created_at\"]        \n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "        handle_list.append(tweet[\"user\"][\"screen_name\"])\n",
    "        text_list.append(tweet[\"text\"])\n",
    "        tweets_ago_list.append(counter)\n",
    "        timestamp_list.append(tweet_time)\n",
    "        \n",
    "# Turn into DataFrame\n",
    "df_cnn=pd.DataFrame(list(zip(handle_list,tweets_ago_list,timestamp_list,\n",
    "                         compound_list,positive_list,negative_list,neutral_list,text_list)))\n",
    "\n",
    "### 02-4: Twitter API Pull for Fox News ####\n",
    "\n",
    "# Target User Account\n",
    "target_account=\"@FoxNews\"\n",
    "\n",
    "for target_user in target_account:\n",
    "    counter = 0\n",
    "\n",
    "timestamp_list = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "text_list = []\n",
    "tweets_ago_list = []\n",
    "handle_list = []\n",
    "\n",
    "for x in range(1, 6):\n",
    "    public_tweets = api.user_timeline(target_account, page=x)\n",
    "    for tweet in public_tweets:\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "        counter+= 1\n",
    "        tweet_time = tweet[\"created_at\"]        \n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "        handle_list.append(tweet[\"user\"][\"screen_name\"])\n",
    "        text_list.append(tweet[\"text\"])\n",
    "        tweets_ago_list.append(counter)\n",
    "        timestamp_list.append(tweet_time)\n",
    "        \n",
    "# Turn into DataFrame\n",
    "df_fox=pd.DataFrame(list(zip(handle_list,tweets_ago_list,timestamp_list,\n",
    "                         compound_list,positive_list,negative_list,neutral_list,text_list)))\n",
    "\n",
    "### 02-5: Twitter API Pull for New York Times ####\n",
    "\n",
    "# Target User Account\n",
    "target_account=\"@nytimes\"\n",
    "\n",
    "for target_user in target_account:\n",
    "    counter = 0\n",
    "\n",
    "timestamp_list = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "text_list = []\n",
    "tweets_ago_list = []\n",
    "handle_list = []\n",
    "\n",
    "for x in range(1, 6):\n",
    "    public_tweets = api.user_timeline(target_account, page=x)\n",
    "    for tweet in public_tweets:\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "        counter+= 1\n",
    "        tweet_time = tweet[\"created_at\"]        \n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "        handle_list.append(tweet[\"user\"][\"screen_name\"])\n",
    "        text_list.append(tweet[\"text\"])\n",
    "        tweets_ago_list.append(counter)\n",
    "        timestamp_list.append(tweet_time)\n",
    "        \n",
    "# Turn into DataFrame\n",
    "df_nyt=pd.DataFrame(list(zip(handle_list,tweets_ago_list,timestamp_list,\n",
    "                         compound_list,positive_list,negative_list,neutral_list,text_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 03: Cleansing DataFrame ####\n",
    "\n",
    "# Combine the DataFrame of 5 different media sources\n",
    "df_all_news=df_bbc.append([df_cbs,df_cnn,df_fox,df_nyt])\n",
    "\n",
    "df_all_news=df_all_news.rename(columns={0:\"Handle\",1:\"Tweets_Ago\",\n",
    "                                        2:\"Timestamp\",3:\"Compound\",4:\"Positive\",5:\"Negative\",6:\"Neutral\",7:\"Text\"})\n",
    "\n",
    "# Export as CSV File\n",
    "df_all_news.to_csv(\"Media_Sentiment.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 04: Data Visualization ####\n",
    "\n",
    "# First Plot: Bar Plot of Media Sentiments\n",
    "news=df_all_news[\"Handle\"].unique()\n",
    "\n",
    "colors=['skyblue','green','red','blue','yellow']\n",
    "\n",
    "\n",
    "for n in range(5):\n",
    "    plt.scatter(x=df_all_news[df_all_news[\"Handle\"]==news[n]][\"Tweets_Ago\"].values,\n",
    "                y=df_all_news[df_all_news[\"Handle\"]==news[n]][\"Compound\"].values,\n",
    "                marker=\"o\", facecolors=\"red\", s=40,\n",
    "                c = colors[n],\n",
    "                label = news[n],\n",
    "                edgecolors=\"grey\", alpha=0.75)\n",
    "\n",
    "\n",
    "plt.ylim(-1, 1)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.title(\"Sentiment Analysis of Media Tweets (Summer 2018)\")\n",
    "plt.legend(title=\"Media Sources\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Figure01.png\")\n",
    "plt.show()\n",
    "\n",
    "# Second Plot: Bar Plot of Media Sentiments\n",
    "\n",
    "bbc_compound=df_bbc[3].mean()\n",
    "cbs_compound=df_cbs[3].mean()\n",
    "cnn_compound=df_cnn[3].mean()\n",
    "fox_compound=df_fox[3].mean()\n",
    "nyt_compound=df_nyt[3].mean()\n",
    "    \n",
    "\n",
    "news=df_all_news[\"Handle\"].unique()\n",
    "cp=[bbc_compound,cbs_compound,cnn_compound,fox_compound,nyt_compound]\n",
    "overall_sentiment=[{'bbc':bbc_compound,'cbs':cbs_compound,'cnn':cnn_compound,'fox':fox_compound,'nyt':nyt_compound}]\n",
    "overall_sentiment=pd.DataFrame(overall_sentiment)\n",
    "overall_sentiment=overall_sentiment.transpose()\n",
    "overall_sentiment=overall_sentiment.reset_index()\n",
    "\n",
    "overall_sentiment=overall_sentiment.rename(columns={\"index\":\"Media\",0:\"Avg_Comp_Sentiment\"})\n",
    "    \n",
    "\n",
    "x_axis=np.arange(len(overall_sentiment))\n",
    "colors={'skyblue','green','red','blue','yellow'}\n",
    "\n",
    "plt.bar(news,cp,alpha=0.5,align=\"center\",width=1,edgecolor=\"black\",color=colors)\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.title(\"Overall Media Sentiment based on Twitter (Summer 2018)\")\n",
    "plt.savefig(\"Figure02.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
